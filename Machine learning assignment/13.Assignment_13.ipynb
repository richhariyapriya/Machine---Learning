{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aa57f2",
   "metadata": {},
   "source": [
    "# Assignment 13 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111120c6",
   "metadata": {},
   "source": [
    "##### 1. Provide an example of the concepts of Prior, Posterior, and Likelihood ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729838a",
   "metadata": {},
   "source": [
    "1. **Prior (Priors):** The prior is the initial belief or probability assigned to an event before taking new evidence into account. In this case, let's say we have a prior belief about the probability that a coin is biased. We may believe that most coins are fair, so our prior belief in the coin being biased might be low. Mathematically, we represent this as \\(P(B)\\), where \\(B\\) is the event that the coin is biased.\n",
    "\n",
    "   Example:\n",
    "   \\[ P(B) = 0.2 \\]\n",
    "   This means that before any new evidence, we believe there is a 20% chance that the coin is biased.\n",
    "\n",
    "2. **Likelihood (Likelihood Function):** The likelihood represents how well the observed data supports a particular hypothesis. In our example, the data would be the result of several coin flips. The likelihood of the data given that the coin is biased (\\(B\\)) is denoted as \\(P(D|B)\\), where \\(D\\) is the data.\n",
    "\n",
    "   Example:\n",
    "   \\[ P(D|B) = 0.8 \\]\n",
    "   This means that if the coin is biased, there is an 80% chance of observing the given data.\n",
    "\n",
    "3. **Posterior (Posterior Probability):** The posterior is the updated probability of the hypothesis after considering the new evidence. It is calculated using Bayes' Theorem:\n",
    "\n",
    "   \\[ P(B|D) = \\frac{P(D|B) \\cdot P(B)}{P(D)} \\]\n",
    "\n",
    "   Where:\n",
    "   - \\(P(B|D)\\) is the posterior probability that the coin is biased given the data.\n",
    "   - \\(P(D|B)\\) is the likelihood of the data given the coin is biased.\n",
    "   - \\(P(B)\\) is the prior probability of the coin being biased.\n",
    "   - \\(P(D)\\) is the probability of observing the data (a normalizing constant).\n",
    "\n",
    "   Example:\n",
    "   \\[ P(B|D) = \\frac{0.8 \\cdot 0.2}{P(D)} \\]\n",
    "   This provides the updated probability of the coin being biased based on the prior belief and the observed data.\n",
    "\n",
    "In this example, as more coin flips are observed, the posterior probability is updated, reflecting our updated belief about the likelihood of the coin being biased. The process of updating beliefs with new evidence is a key aspect of Bayesian inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae857d4",
   "metadata": {},
   "source": [
    "##### 2. What role does Bayes' theorem play in the concept learning principle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac0413",
   "metadata": {},
   "source": [
    "In the concept learning principle, Bayes' theorem is fundamental for updating beliefs. It provides a mathematical framework for adjusting prior beliefs based on new evidence, facilitating a probabilistic and iterative learning process. Bayes' theorem helps handle uncertainty, formalizes learning as a probabilistic inference, and ensures optimal belief updates in the face of evolving information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981ac1e",
   "metadata": {},
   "source": [
    "##### 3. Offer an example of how the Nave Bayes classifier is used in real life ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677c5a4b",
   "metadata": {},
   "source": [
    "In real life, a common application of the Naive Bayes classifier is in spam email filtering. The classifier uses the probability of certain words appearing in spam and non-spam emails to classify incoming emails as either spam or not spam. It assumes that the presence of each word in an email is independent of the presence of other words, hence the term \"naive.\" The classifier is trained on a dataset of labeled emails, learning the probabilities associated with different words in spam and non-spam contexts. Once trained, it can effectively categorize new emails, helping filter out unwanted spam messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2a64",
   "metadata": {},
   "source": [
    "##### 4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about doing it ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2b68a",
   "metadata": {},
   "source": [
    "Yes, Naive Bayes classifiers can be used with continuous numeric data. One common approach is to assume a probability distribution (e.g., Gaussian distribution) for the continuous features. Here's a brief overview of how you can use Naive Bayes with continuous numeric data:\n",
    "\n",
    "1. **Assume a Probability Distribution:**\n",
    "   - For each class, assume a probability distribution (e.g., Gaussian) for each continuous feature. This distribution is typically characterized by its mean and standard deviation.\n",
    "\n",
    "2. **Estimate Parameters:**\n",
    "   - Calculate the mean and standard deviation of each feature for each class based on the training data.\n",
    "\n",
    "3. **Probability Density Function (PDF):**\n",
    "   - Use the probability density function associated with the chosen distribution to calculate the likelihood of observing a specific value for each feature given the class.\n",
    "\n",
    "4. **Product of Likelihoods:**\n",
    "   - Since Naive Bayes assumes independence between features, calculate the product of the likelihoods for all features.\n",
    "\n",
    "5. **Prior Probability:**\n",
    "   - Multiply the product of likelihoods by the prior probability of the class to get the unnormalized posterior probability.\n",
    "\n",
    "6. **Normalization:**\n",
    "   - Normalize the probabilities across all classes to obtain the final posterior probabilities.\n",
    "\n",
    "This process allows the Naive Bayes classifier to handle continuous numeric data by making assumptions about the underlying probability distributions of the features. Keep in mind that the \"naive\" assumption of independence between features may not always hold in real-world scenarios. However, despite its simplicity, Naive Bayes often performs well, especially with limited data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2162e",
   "metadata": {},
   "source": [
    "##### 5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they capable of resolving a wide range of issues ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621b232",
   "metadata": {},
   "source": [
    "**Bayesian Belief Networks (BBNs):**\n",
    "\n",
    "- **Definition:** Bayesian Belief Networks, or Bayesian Networks, are graphical models that represent probabilistic relationships among a set of variables. They use directed acyclic graphs to illustrate dependencies between variables, along with conditional probability tables to quantify these dependencies.\n",
    "\n",
    "- **How They Work:**\n",
    "  - Nodes in the graph represent random variables, and edges represent probabilistic dependencies.\n",
    "  - Conditional probability tables specify the probability of a node given its parents in the graph.\n",
    "  - BBNs leverage Bayes' theorem to update beliefs as new evidence becomes available.\n",
    "\n",
    "- **Applications:**\n",
    "  - **Diagnosis and Prediction:** Used in medical diagnosis, fault diagnosis, and predictive modeling.\n",
    "  - **Risk Assessment:** Applied in finance, insurance, and project management for risk assessment.\n",
    "  - **Speech Recognition:** Used to model phonetic dependencies in speech recognition systems.\n",
    "  - **Natural Language Processing:** For language understanding and semantic analysis.\n",
    "  - **Image Processing:** Applied in image recognition and computer vision.\n",
    "  - **Environmental Modeling:** Used to model and analyze complex environmental systems.\n",
    "\n",
    "- **Capabilities:**\n",
    "  - **Handling Uncertainty:** BBNs are well-suited for modeling and reasoning in situations involving uncertainty and incomplete information.\n",
    "  - **Decision Support:** They facilitate decision-making by providing a structured way to incorporate probabilities and dependencies.\n",
    "  - **Versatility:** BBNs are versatile and can represent a wide range of real-world systems.\n",
    "\n",
    "In short, Bayesian Belief Networks are graphical models that use probability theory to represent and reason about uncertain knowledge. They find applications in diverse domains due to their ability to model complex relationships and handle uncertainty effectively. While powerful, their effectiveness depends on the accuracy of the specified relationships and the availability of reliable data for parameter estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96163dd",
   "metadata": {},
   "source": [
    "##### 6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98 and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered, implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) = 0.00001. What are the chances that an alarm would be triggered when an individual is actually an intruder ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc6757",
   "metadata": {},
   "source": [
    "In this scenario, you are looking to find the probability that an alarm is triggered given that an individual is actually an intruder. This corresponds to the conditional probability \\( P(A = 1 | I = 1) \\).\n",
    "\n",
    "According to the information provided:\n",
    "\n",
    "\\[ P(A = 1 | I = 1) = 0.98 \\]\n",
    "\n",
    "This means that the probability of the alarm being triggered when there is an intruder is 0.98.\n",
    "\n",
    "So, the chances that an alarm would be triggered when an individual is actually an intruder are \\( \\boxed{0.98} \\) or 98%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b649e",
   "metadata": {},
   "source": [
    "##### 7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune (random variable D) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536981c",
   "metadata": {},
   "source": [
    "In this scenario, we want to calculate the probability that a person who tests positive is actually immune to the antibiotic. Let's denote:\n",
    "\n",
    "- \\( D = 1 \\) for being immune (positive outcome).\n",
    "- \\( D = 0 \\) for not being immune (negative outcome).\n",
    "\n",
    "Similarly, let \\( T = 1 \\) represent a positive test result, and \\( T = 0 \\) represent a negative test result.\n",
    "\n",
    "We are given the following probabilities:\n",
    "\n",
    "\\[ P(T = 1 | D = 0) = 0.01 \\]  (False positive rate - the probability of testing positive given that the person is not immune)\n",
    "\\[ P(T = 0 | D = 1) = 0.05 \\]  (False negative rate - the probability of testing negative given that the person is immune)\n",
    "\\[ P(D = 1) = 0.02 \\]  (Prevalence - the probability of being immune)\n",
    "\n",
    "We want to find \\( P(D = 1 | T = 1) \\) - the probability of being immune given a positive test result.\n",
    "\n",
    "Using Bayes' Theorem:\n",
    "\n",
    "\\[ P(D = 1 | T = 1) = \\frac{P(T = 1 | D = 1) \\cdot P(D = 1)}{P(T = 1)} \\]\n",
    "\n",
    "We can find \\( P(T = 1) \\) by using the law of total probability:\n",
    "\n",
    "\\[ P(T = 1) = P(T = 1 | D = 0) \\cdot P(D = 0) + P(T = 1 | D = 1) \\cdot P(D = 1) \\]\n",
    "\n",
    "\\[ P(T = 1) = 0.01 \\cdot (1 - 0.02) + (1 - 0.05) \\cdot 0.02 \\]\n",
    "\n",
    "Now, we can substitute these values into the Bayes' Theorem formula:\n",
    "\n",
    "\\[ P(D = 1 | T = 1) = \\frac{(1 - 0.05) \\cdot 0.02}{0.01 \\cdot (1 - 0.02) + (1 - 0.05) \\cdot 0.02} \\]\n",
    "\n",
    "Calculating this expression will give you the likelihood that a person who tests positive is actually immune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54020cf8",
   "metadata": {},
   "source": [
    "##### 8. In order to prepare for the test, a student knows that there will be one question in the exam that is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and 50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10 type B problems, and 6 of 10 type C problems.\n",
    "1. What is the likelihood that the student can solve the exam problem?\n",
    "2. Given the student's solution, what is the likelihood that the problem was of form A?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30532b78",
   "metadata": {},
   "source": [
    "Let's denote the events:\n",
    "\n",
    "- \\( A \\): The event that the exam problem is of form A.\n",
    "- \\( B \\): The event that the exam problem is of form B.\n",
    "- \\( C \\): The event that the exam problem is of form C.\n",
    "\n",
    "Also, let \\( S \\) be the event that the student can solve the exam problem.\n",
    "\n",
    "The probabilities of each form are given:\n",
    "\n",
    "\\[ P(A) = 0.3 \\]\n",
    "\\[ P(B) = 0.2 \\]\n",
    "\\[ P(C) = 0.5 \\]\n",
    "\n",
    "Now, let's denote \\( P(S|A) \\), \\( P(S|B) \\), and \\( P(S|C) \\) as the probabilities that the student can solve the problem given the form:\n",
    "\n",
    "\\[ P(S|A) = \\frac{\\text{Number of type A problems solved}}{\\text{Total number of type A problems}} = \\frac{9}{10} \\]\n",
    "\\[ P(S|B) = \\frac{\\text{Number of type B problems solved}}{\\text{Total number of type B problems}} = \\frac{2}{10} \\]\n",
    "\\[ P(S|C) = \\frac{\\text{Number of type C problems solved}}{\\text{Total number of type C problems}} = \\frac{6}{10} \\]\n",
    "\n",
    "Now, we can use Bayes' Theorem to calculate the likelihood of the student solving the exam problem (\\( P(S) \\)) and the likelihood that the problem was of form A given the student's solution (\\( P(A|S) \\)):\n",
    "\n",
    "\\[ P(S) = P(A) \\cdot P(S|A) + P(B) \\cdot P(S|B) + P(C) \\cdot P(S|C) \\]\n",
    "\n",
    "\\[ P(A|S) = \\frac{P(A) \\cdot P(S|A)}{P(S)} \\]\n",
    "\n",
    "You can substitute the values and calculate these probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db681d1",
   "metadata": {},
   "source": [
    "##### 9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "2. On a daily basis, how many fake photographs (photographs taken when there is no customer) and how many missed photographs (photographs taken when there is a customer) are there?\n",
    "3. Explain likelihood that there is a customer if there is a photograph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9621946",
   "metadata": {},
   "source": [
    "Let's break down the information given:\n",
    "\n",
    "1. **Number of Customers in a 5-Minute Period:**\n",
    "   - Probability of a customer arriving in a 5-minute period: \\( P(\\text{Customer}) = 0.05 \\).\n",
    "   - Probability of no customer arriving in a 5-minute period: \\( P(\\text{No Customer}) = 1 - P(\\text{Customer}) = 0.95 \\).\n",
    "\n",
    "2. **Detection by CCTV:**\n",
    "   - Probability of detecting a customer if there is one: \\( P(\\text{Detection | Customer}) = 0.99 \\).\n",
    "   - Probability of a false detection if there is no customer: \\( P(\\text{False Detection | No Customer}) = 0.10 \\).\n",
    "\n",
    "3. **Daily Basis (10 hours):**\n",
    "   - There are \\( \\frac{10 \\times 60}{5} = 120 \\) five-minute bins in 10 hours.\n",
    "\n",
    "4. **Calculations:**\n",
    "\n",
    "   a. **Number of Customers:**\n",
    "      - Expected number of customers in a 5-minute bin: \\( 0.05 \\times 1 = 0.05 \\).\n",
    "      - Expected number of customers in 120 bins (10 hours): \\( 0.05 \\times 120 = 6 \\) customers.\n",
    "\n",
    "   b. **Number of Fake Photographs:**\n",
    "      - Expected number of false detections in a 5-minute bin: \\( 0.95 \\times 0.10 = 0.095 \\).\n",
    "      - Expected number of false detections in 120 bins (10 hours): \\( 0.095 \\times 120 = 11.4 \\) false photographs.\n",
    "\n",
    "   c. **Number of Missed Photographs:**\n",
    "      - Expected number of missed detections in a 5-minute bin: \\( 0.05 \\times 0.01 = 0.0005 \\).\n",
    "      - Expected number of missed detections in 120 bins (10 hours): \\( 0.0005 \\times 120 = 0.06 \\) missed photographs.\n",
    "\n",
    "5. **Likelihood of a Customer given a Photograph:**\n",
    "   - Using Bayes' Theorem:\n",
    "     \\[ P(\\text{Customer | Photograph}) = \\frac{P(\\text{Photograph | Customer}) \\times P(\\text{Customer})}{P(\\text{Photograph})} \\]\n",
    "     \\[ P(\\text{Photograph}) = P(\\text{Photograph | Customer}) \\times P(\\text{Customer}) + P(\\text{Photograph | No Customer}) \\times P(\\text{No Customer}) \\]\n",
    "   - Substitute the known values and calculate.\n",
    "\n",
    "In summary:\n",
    "- On a daily basis, approximately 6 customers come into the bank.\n",
    "- There are around 11.4 fake photographs (false detections) and 0.06 missed photographs.\n",
    "- The likelihood of a customer being present given a photograph can be calculated using Bayes' Theorem and the provided probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b686929",
   "metadata": {},
   "source": [
    "##### 10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief network to represent the conditional independence assumptions of the Nave Bayes classifier for the match winning prediction problem in Section 6.4.4.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f51f2",
   "metadata": {},
   "source": [
    "Creating a Conditional Probability Table (CPT) for the node \"Won Toss\" in a Bayesian Belief Network involves specifying the probabilities of winning the match based on whether the team won or lost the toss. Assuming that winning or losing the toss is independent of other factors given the match outcome, the CPT for \"Won Toss\" might look like this:\n",
    "\n",
    "\\[ P(\\text{Won Toss} | \\text{Match Outcome}) \\]\n",
    "\n",
    "\\[\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\text{Match Outcome} & P(\\text{Won Toss}) \\\\\n",
    "\\hline\n",
    "\\text{Win} & p_1 \\\\\n",
    "\\hline\n",
    "\\text{Lose} & p_2 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\]\n",
    "\n",
    "Here:\n",
    "- \\( p_1 \\) represents the probability of winning the toss given that the team wins the match.\n",
    "- \\( p_2 \\) represents the probability of winning the toss given that the team loses the match.\n",
    "\n",
    "This table assumes that the outcome of winning the toss is conditionally independent of other factors given the match outcome. In a Naive Bayes classifier, this independence assumption simplifies the modeling process, making it computationally more efficient. Note that in more complex scenarios, dependencies among variables might be considered, but in a Naive Bayes context, we often assume independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfbecff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
